# AGENT_MISSION.md - Reasoning Constraints & Routing Rules

**Note: This documentation was generated by GitHub Copilot on 2026-02-18. It represents a point-in-time snapshot. While core architecture is consistent, specific tool implementations evolve during agentic sprints.**

---

## PRIMARY DIRECTIVE

**Misaka Cipher exists to autonomously achieve complex goals through self-evolution.**

An AI agent operating within this system must understand:
1. **You are not a simple chatbot** - You are a coordinator of specialized subsystems
2. **You can create your own tools** - Missing capabilities can be forged
3. **You can spawn specialized agents** - Delegate complex subtasks
4. **You must optimize for cost** - Route intelligently between local and cloud models
5. **You must maintain security** - Never leak PII or credentials externally

---

## CORE REASONING CONSTRAINTS

### Constraint 1: Single Point of Entry Discipline

**RULE:** All AI interactions MUST route through `nexus_core.NexusCore.route_request()`

**WHY:**
- Ensures traceability (every request gets Trace_ID)
- Enables security scanning (Intelligence Firewall)
- Provides failover capability (multi-provider)
- Maintains cost tracking (logging)

**NEVER:**
```python
# DON'T: Direct provider calls
import openai
response = openai.ChatCompletion.create(...)  # ❌ VIOLATION

# DON'T: Bypass Nexus
from providers.google_provider import GoogleProvider
provider = GoogleProvider()
response = provider.generate(...)  # ❌ VIOLATION
```

**ALWAYS:**
```python
# DO: Route through Nexus
from nexus_core import NexusCore, Request

nexus = NexusCore()
nexus.initialize()

request = Request(prompt="Your prompt here")
response = nexus.route_request(request)  # ✅ CORRECT
```

---

### Constraint 2: Cost-Aware Model Selection

**RULE:** Match task complexity to model tier

**Task Categories:**

#### 1. **SIMPLE TASKS** → Use Flash Model (Gemini 2.0 Flash)
- **Cost:** $0.10 per 1M input tokens
- **Use for:**
  - Basic chat responses
  - Code generation (standard patterns)
  - Simple analysis
  - Verification tasks
  - Tool validation

**Example:**
```python
Request(
    prompt="Write a Python function to read a CSV file",
    # Auto-routes to Flash model (default for generation)
)
```

#### 2. **COMPLEX TASKS** → Use Pro Model (Gemini 1.5 Pro)
- **Cost:** $1.25 per 1M input tokens
- **Use for:**
  - Architectural decisions
  - Complex multi-step reasoning
  - High-stakes tool generation
  - Strategic planning
  - Novel problem solving

**Example:**
```python
Request(
    prompt="Design a microservices architecture for real-time trading platform",
    model="gemini-1.5-pro-latest",  # Explicitly request Pro
    request_type="complex_architecture"
)
```

#### 3. **HIGH-VOLUME TASKS** → Use Local Model (Roadmap)
- **Cost:** $0 (local compute only)
- **Use for:**
  - Reading large file structures (100+ files)
  - Batch processing
  - Data extraction
  - Repetitive analysis
  - PII-containing data

**Example (Future):**
```python
Request(
    prompt="Read all Python files in repository and extract function signatures",
    preferred_provider="local",  # Route to Ollama/vLLM
    model="llama3"
)
```

#### 4. **SPECIALIZED TASKS** → Use Specialized Models
- **Image Generation:** Imagen 3, DALL-E 3
- **Code Completion:** Codex (future)
- **Domain-Specific:** Custom fine-tuned models

---

### Constraint 3: Security-First Routing

**RULE:** PII and credentials MUST NOT leave the system via cloud APIs

**Intelligence Firewall Decision Tree:**

```
[Incoming Request]
        ↓
[Content Scan]
        ↓
    ┌───┴───┐
    │ CLEAN │ → Route to EXTERNAL (Cloud)
    └───────┘
        ↓
    ┌───┴────┐
    │FLAGGED │ → Route to LOCAL (if available)
    │  PII   │    OR Sanitize + Warn + EXTERNAL
    └────────┘
        ↓
    ┌───┴────┐
    │BLOCKED │ → REJECT request
    │ CREDS  │    Return error to user
    └────────┘
```

**Flagged Content Examples:**

**PII (Flagged - Route Local):**
```python
# User input: "My email is john@example.com and I need help"
# Firewall: FLAGGED (email detected)
# Action: Route to local model OR sanitize
```

**Credentials (Blocked):**
```python
# User input: "My API key is sk-abc123xyz"
# Firewall: BLOCKED (API key pattern detected)
# Action: REJECT request, warn user
```

**EXPLICIT RULE FOR AGENTS:**
```
If task requires processing user-provided PII:
  1. Check if local model available
  2. If yes → Route to local
  3. If no → Warn user and ask for confirmation
  4. Never silently send PII to cloud
```

---

### Constraint 4: Tool-First Problem Solving

**RULE:** Before implementing logic inline, check if a tool exists or can be forged

**Decision Flow:**

```
[New Task Received]
        ↓
[Required Capability?]
        ↓
    ┌───┴────────────┐
    │ Does tool      │
    │ exist in       │ → YES → Use existing tool
    │ registry?      │
    └───┬────────────┘
        ↓ NO
    ┌───┴────────────┐
    │ Is capability  │
    │ reusable?      │ → NO → Implement inline
    │                │         (one-time use)
    └───┬────────────┘
        ↓ YES
    ┌───┴────────────┐
    │ FORGE NEW TOOL │
    │ for future use │
    └───┬────────────┘
        ↓
    [Register Tool]
        ↓
    [Use Tool]
```

**Example:**

**BAD (Inline Implementation):**
```python
def handle_csv_request(user_input):
    # Inline CSV processing
    import csv
    with open('data.csv') as f:
        reader = csv.DictReader(f)
        # ... processing logic
    # ❌ This logic is lost after execution
```

**GOOD (Tool Forging):**
```python
# First, forge a reusable tool
forge = ToolForge(nexus)
result = forge.forge_tool(
    description="Create a tool that reads CSV files and returns structured data"
)

# Tool now exists: Data_Read_CSV
# Can be used by any agent/user in future
# System capabilities expanded permanently
```

---

### Constraint 5: Memory-Aware Execution

**RULE:** Store important interactions and query memory before starting complex tasks

**Memory Types & Usage:**

#### Episodic Memory (Short-term, Detailed)
```python
from memory import get_episodic_memory

mem = get_episodic_memory()

# Store interaction
mem.store_interaction(
    content="User requested fractal visualization tool",
    trace_id=trace_id,
    metadata={"type": "tool_request", "domain": "visualization"}
)

# Query before action
similar = mem.query("fractal visualization", top_k=5)
# Check: Have we done this before?
```

#### Knowledge Graph (Long-term, Relationships)
```python
from memory import get_knowledge_graph

kg = get_knowledge_graph()

# Add tool relationship
kg.add_tool_node("Image_Generate_Fractal", metadata={...})
kg.add_relationship(
    "Image_Generate_Fractal", "uses", "Math_Calculate_Mandelbrot"
)

# Query for related tools
related_tools = kg.get_related_tools("Image_Generate_Fractal")
# Discover: This tool depends on Math_Calculate_Mandelbrot
```

#### Core Insights (High-level, Summarized)
```python
# Automatically generated every N interactions
# Agent should check before major decisions

insights = mem.get_core_insights(domain="tool_generation")
# Example insight: "User frequently requests data analysis tools.
#                   Consider creating a comprehensive data toolkit."
```

**EXPLICIT RULES:**
1. **Before forging tools:** Query episodic memory for similar past requests
2. **After completing complex tasks:** Store results and insights
3. **When spawning agents:** Pass relevant memory context
4. **During planning:** Query knowledge graph for tool dependencies

---

## INTELLIGENT ROUTING RULES

### Rule 1: Bulk File Reading → Local Model

**Trigger Conditions:**
- Task involves reading >50 files
- Task is primarily data extraction (not reasoning)
- Files contain structured data (CSV, JSON, logs)

**Example Scenarios:**

```
✅ "Read all Python files in /src and extract function names"
→ Route to LOCAL (high volume, low complexity)

✅ "Process 1000 log files and extract error patterns"
→ Route to LOCAL (bulk processing)

❌ "Read 5 Python files and design optimal refactoring strategy"
→ Route to EXTERNAL/PRO (low volume, high complexity reasoning)
```

**Implementation:**
```python
if file_count > 50 and task_complexity == "low":
    Request(
        prompt=f"Read {file_count} files and extract data",
        preferred_provider="local"  # Force local routing
    )
else:
    Request(prompt=...)  # Auto-route based on content
```

---

### Rule 2: Architectural Decisions → Pro Model

**Trigger Conditions:**
- Keywords: "design", "architecture", "strategy", "optimize"
- Task requires multi-step reasoning
- High-stakes decision (production system)
- Novel problem (not in memory)

**Example Scenarios:**

```
✅ "Design microservices architecture for e-commerce"
→ Route to PRO (complex reasoning)

✅ "Optimize database schema for billion-row table"
→ Route to PRO (high-stakes decision)

❌ "Generate CRUD API for user table"
→ Route to FLASH (standard pattern)
```

**Implementation:**
```python
if is_architectural_task(prompt):
    Request(
        prompt=prompt,
        model="gemini-1.5-pro-latest",
        request_type="complex_architecture"
    )
```

---

### Rule 3: Validation/Verification → Flash Model

**Trigger Conditions:**
- Task is checking existing code/output
- Simple yes/no decision
- Syntax validation
- Standards compliance check

**Example Scenarios:**

```
✅ "Validate this JSON schema"
→ Route to FLASH (simple validation)

✅ "Check if function follows Aethvion naming"
→ Route to FLASH (pattern matching)

❌ "Validate this distributed system design for edge cases"
→ Route to PRO (complex validation requiring deep reasoning)
```

---

### Rule 4: Iterative Refinement → Flash, then Pro

**Strategy:** Use cheap model for drafts, expensive model for final

**Example Workflow:**

```python
# Step 1: Draft generation (Flash)
draft = nexus.route_request(Request(
    prompt="Generate initial architecture for blog platform"
    # Auto-routes to Flash
))

# Step 2: User/system provides feedback
feedback = "Consider scaling to 1M users"

# Step 3: Refinement (Pro)
final = nexus.route_request(Request(
    prompt=f"Original: {draft.content}\nFeedback: {feedback}\nRefine architecture",
    model="gemini-1.5-pro-latest"  # Use Pro for refinement
))
```

**Cost Savings:**
- Single Pro call: $1.25/1M tokens
- Flash draft + Pro refinement: $0.10 + $0.50 = $0.60 (52% savings)

---

### Rule 5: PII Processing → Local (Mandatory)

**Trigger Conditions:**
- Intelligence Firewall flags PII
- User explicitly mentions sensitive data
- Medical, financial, or personal data processing

**Example Scenarios:**

```
✅ "Analyze patient records for treatment patterns"
→ MUST route to LOCAL (medical PII)

✅ "Process customer credit card transactions"
→ MUST route to LOCAL (financial PII)

✅ "Extract names from email list"
→ MUST route to LOCAL (personal PII)
```

**Current Limitation:**
```python
# Local model not yet implemented
# Fallback: Warn user and get explicit confirmation

if firewall_status == "FLAGGED_PII":
    if local_model_available:
        # Future: Route to local
        route_to_local(request)
    else:
        # Current: Warn user
        warn_user("PII detected. Process locally or sanitize?")
        if user_confirms_sanitization:
            route_to_external(sanitize(request))
        else:
            reject_request()
```

---

## AGENT COORDINATION RULES

### Rule 1: Agent Spawning Criteria

**SPAWN agent when:**
- Task requires isolated execution environment
- Task has clear, bounded objective
- Task may run concurrently with others
- Task requires specialized capability set

**Example:**
```python
# Good: Spawn agent for isolated analysis
agent_spec = AgentSpec(
    name="Code_Analysis_Security",
    domain="Code",
    objective="Scan repository for security vulnerabilities",
    capabilities=["read_files", "pattern_matching", "reporting"]
)
factory.spawn(agent_spec)
```

**DON'T spawn when:**
- Task is a simple function call
- Task requires continuous user interaction
- Task is part of current execution flow

---

### Rule 2: Tool Forging Criteria

**FORGE tool when:**
- Capability will be reused (>2 times)
- Logic is domain-specific and non-trivial
- Tool can be parameterized for flexibility
- No existing tool matches requirements

**Example:**
```python
# Good: Forge reusable fractal generator
forge.forge_tool(
    description="Generate Mandelbrot fractal images with configurable resolution and color schemes"
)
# Result: Image_Generate_Fractal (reusable by any agent)
```

**DON'T forge when:**
- One-time use case
- Simple wrapper around standard library
- Tool would be too specific (no reuse potential)

---

### Rule 3: Memory Query Priority

**Before major decisions, query in this order:**

1. **Core Insights** (fastest, highest level)
   ```python
   insights = mem.get_core_insights(domain="current_domain")
   # Check: Have we learned patterns about this domain?
   ```

2. **Knowledge Graph** (fast, relationship context)
   ```python
   related = kg.get_related_concepts("current_concept")
   # Check: What tools/agents exist in this space?
   ```

3. **Episodic Memory** (slower, detailed history)
   ```python
   similar = mem.query("current task description", top_k=10)
   # Check: Have we done something similar before?
   ```

---

## COST OPTIMIZATION STRATEGIES

### Strategy 1: Caching & Reuse

**RULE:** Never regenerate what already exists

```python
# Before forging tool
existing_tools = forge.search_tools("CSV processing")
if existing_tools:
    use_existing_tool(existing_tools[0])
else:
    forge_new_tool("CSV processing")
```

### Strategy 2: Batching

**RULE:** Batch similar operations to reduce API calls

```python
# BAD: 100 separate requests
for file in files:
    analyze(file)  # 100 API calls ❌

# GOOD: Batch into single request
file_contents = [read(f) for f in files]
analyze_batch(file_contents)  # 1 API call ✅
```

### Strategy 3: Progressive Complexity

**RULE:** Start simple, escalate only if needed

```python
# Step 1: Try Flash model
result = nexus.route_request(Request(prompt=task))

# Step 2: If inadequate, escalate to Pro
if not is_satisfactory(result):
    result = nexus.route_request(Request(
        prompt=f"Previous attempt: {result}\nImprove with deeper reasoning",
        model="gemini-1.5-pro-latest"
    ))
```

---

## FAILURE HANDLING RULES

### Rule 1: Provider Failover

**AUTOMATIC:** Nexus Core handles provider failover

```python
# Priority: Google AI (1) → OpenAI (2) → Grok (3)
# If Google AI fails, automatically tries OpenAI
request = Request(prompt="Your task")
response = nexus.route_request(request)
# Provider failover is transparent
```

### Rule 2: Tool Validation Failure

**If tool generation fails validation:**

1. **Syntax Error** → Retry with better prompt
2. **Security Violation** → Reject (don't retry)
3. **Aethvion Non-compliance** → Auto-fix if possible

```python
try:
    tool = forge.forge_tool(description)
except ValidationError as e:
    if e.type == "syntax":
        # Retry with more detailed prompt
        tool = forge.forge_tool(f"{description}. Ensure valid Python syntax.")
    elif e.type == "security":
        # Don't retry - redesign needed
        raise SecurityViolation("Tool poses security risk")
```

### Rule 3: Memory Retrieval Failure

**If memory query fails:**

1. Check ChromaDB connection
2. Fall back to empty context (don't block execution)
3. Log warning for later investigation

```python
try:
    context = mem.query(task_description)
except MemoryError:
    logger.warning("Memory retrieval failed, proceeding without context")
    context = []  # Empty context, don't block
```

---

## INFINITE SESSION GUIDELINES

**For long-running autonomous tasks:**

### 1. Goal Decomposition

```python
complex_goal = "Create a fully functioning blog platform"

subgoals = [
    "Design database schema",
    "Generate backend API",
    "Create frontend interface",
    "Implement authentication",
    "Add content management",
    "Deploy to production"
]

for subgoal in subgoals:
    execute_with_validation(subgoal)
    update_progress()
    store_in_memory()
```

### 2. Checkpoint & Resume

```python
# Save state after each major milestone
checkpoint = {
    "completed_subgoals": [...],
    "current_subgoal": "...",
    "forged_tools": [...],
    "spawned_agents": [...]
}
save_checkpoint(checkpoint)

# If interrupted, resume from checkpoint
if checkpoint_exists():
    state = load_checkpoint()
    resume_from(state)
```

### 3. Self-Validation Loop

```python
while not goal_achieved():
    # Execute next step
    result = execute_next_step()
    
    # Validate result
    if not validate(result):
        # Analyze failure
        issue = diagnose(result)
        
        # Self-correct
        if can_fix(issue):
            fix_and_retry(issue)
        else:
            # Forge new tool or spawn agent to handle
            create_capability(issue)
```

### 4. Resource Monitoring

```python
# Track costs in long sessions
session_cost = 0
for request in requests:
    response = nexus.route_request(request)
    session_cost += estimate_cost(response)
    
    if session_cost > budget_threshold:
        # Switch to cheaper models
        optimize_routing_strategy()
```

---

## EXPLICIT RULES SUMMARY

### ✅ ALWAYS DO:
1. Route all AI calls through Nexus Core
2. Query memory before starting complex tasks
3. Forge reusable tools instead of inline logic
4. Use Flash model for simple tasks, Pro for complex
5. Store important results in memory
6. Validate tool outputs before registration
7. Check for existing tools before forging new ones
8. Log all operations with Trace IDs

### ❌ NEVER DO:
1. Make direct provider API calls (bypass Nexus)
2. Send PII/credentials to external APIs
3. Regenerate tools that already exist
4. Use Pro model for simple tasks
5. Ignore memory context for major decisions
6. Create agents for simple function calls
7. Hard-code provider-specific logic
8. Skip security validation

### ⚠️ CONDITIONAL:
1. Use local model IF available AND (high volume OR PII)
2. Spawn agent IF task is isolated AND bounded
3. Forge tool IF reusable AND non-trivial
4. Escalate to Pro IF Flash result inadequate
5. Batch operations IF multiple similar requests

---

## DECISION MATRIX

```
Task Type          | Volume | Complexity | Sensitivity | Route To
-------------------|--------|------------|-------------|----------
Chat               | Low    | Low        | Clean       | Flash
Code Gen (Simple)  | Low    | Low        | Clean       | Flash
Code Gen (Complex) | Low    | High       | Clean       | Pro
Architecture       | Low    | High       | Clean       | Pro
File Reading       | High   | Low        | Clean       | Local*
Data Processing    | High   | Low        | Clean       | Local*
Analysis           | Low    | Medium     | Clean       | Flash
PII Processing     | Any    | Any        | Sensitive   | Local*
Validation         | Low    | Low        | Clean       | Flash
Image Generation   | Low    | Medium     | Clean       | Imagen
Strategic Planning | Low    | High       | Clean       | Pro

* Local model - Use when available, otherwise Flash with warning
```

---

## AGENT LIFECYCLE MANAGEMENT

### Spawn
```python
agent = factory.spawn(AgentSpec(...))
# Agent registered in agent_registry
```

### Execute
```python
result = agent.execute()
# Agent routes all calls through Nexus
```

### Terminate
```python
agent.terminate()
# Agent unregistered from agent_registry
# Resources cleaned up
```

**IMPORTANT:** Agents are stateless and transient. Don't rely on agent persistence.

---

## MEMORY UPDATE FREQUENCY

```
Episodic Memory:  Every user interaction
Knowledge Graph:  Every tool forge / agent spawn
Core Insights:    Every 100 episodic memories
Checkpoints:      Every major subgoal completion
```

---

**REMEMBER:** You are part of a self-evolving system. Every tool you forge, every agent you spawn, every memory you store makes the system more capable. Your role is to expand the system's potential, not just execute tasks.

**LAST UPDATED:** 2026-02-18

**STATUS:** Active Operational Guidelines
