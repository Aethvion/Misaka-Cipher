"""
Misaka Cipher - Usage Tracker
Tracks API calls, token usage, and estimated costs.
"""

import json
import threading
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from collections import defaultdict

from utils import get_logger

logger = get_logger(__name__)

_instance = None
_lock = threading.Lock()

MAX_LOG_ENTRIES = 10000
DATA_DIR = Path(__file__).parent.parent / "data"
USAGE_LOG_FILE = DATA_DIR / "usage_log.json"


def get_usage_tracker():
    """Get or create the singleton UsageTracker."""
    global _instance
    if _instance is None:
        with _lock:
            if _instance is None:
                _instance = UsageTracker()
    return _instance


class UsageTracker:
    """Tracks all API usage: calls, tokens, costs."""

    def __init__(self):
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        self._log: List[Dict[str, Any]] = self._load_log()
        self._model_costs = self._load_model_costs()
        logger.info(f"UsageTracker initialized ({len(self._log)} existing entries)")

    def _load_log(self) -> List[Dict[str, Any]]:
        """Load existing usage log from disk."""
        try:
            if USAGE_LOG_FILE.exists():
                with open(USAGE_LOG_FILE, "r") as f:
                    data = json.load(f)
                return data if isinstance(data, list) else []
        except Exception as e:
            logger.warning(f"Could not load usage log: {e}")
        return []

    def _save_log(self):
        """Persist usage log to disk (capped)."""
        try:
            # Keep only the most recent entries
            trimmed = self._log[-MAX_LOG_ENTRIES:]
            with open(USAGE_LOG_FILE, "w") as f:
                json.dump(trimmed, f, indent=2)
        except Exception as e:
            logger.error(f"Failed to save usage log: {e}")

    def _load_model_costs(self) -> Dict[str, Dict[str, float]]:
        """Load per-model input/output cost data from model_registry.json."""
        costs = {}
        try:
            registry_path = Path(__file__).parent.parent / "config" / "model_registry.json"
            if registry_path.exists():
                with open(registry_path, "r") as f:
                    registry = json.load(f)
                for provider_name, provider_cfg in registry.get("providers", {}).items():
                    for model_key, model_info in provider_cfg.get("models", {}).items():
                        if isinstance(model_info, dict):
                            model_id = model_info.get("id", model_key)
                            # New per-1M format
                            input_cost = model_info.get("input_cost_per_1m_tokens", 0.0)
                            output_cost = model_info.get("output_cost_per_1m_tokens", 0.0)
                            # Backward compat: convert old per-1k to per-1M
                            if input_cost == 0 and output_cost == 0:
                                legacy = model_info.get("cost_per_1k_tokens", 0.0)
                                if legacy:
                                    input_cost = legacy * 1000
                                    output_cost = legacy * 1000
                            costs[model_id] = {
                                "input": input_cost,
                                "output": output_cost
                            }
        except Exception as e:
            logger.warning(f"Could not load model costs: {e}")
        return costs

    def estimate_tokens(self, text: str) -> int:
        """Estimate token count from text length (approx 1 token â‰ˆ 4 chars)."""
        if not text:
            return 0
        return max(1, len(text) // 4)

    def log_api_call(
        self,
        provider: str,
        model: str,
        prompt: str,
        response_content: str,
        trace_id: str,
        operation: str = "chat",
        success: bool = True,
        metadata: Optional[Dict[str, Any]] = None,
        source: str = "chat"
    ):
        """Log an API call with token and cost estimation."""
        metadata = metadata or {}

        # Extract or estimate token counts
        usage_data = metadata.get("usage", {})
        prompt_tokens = usage_data.get("prompt_tokens") or usage_data.get("prompt_token_count") or self.estimate_tokens(prompt)
        completion_tokens = usage_data.get("completion_tokens") or usage_data.get("candidates_token_count") or self.estimate_tokens(response_content)
        total_tokens = usage_data.get("total_tokens") or (prompt_tokens + completion_tokens)

        # Estimate cost (per 1M tokens)
        model_costs = self._model_costs.get(model, {"input": 0.0, "output": 0.0})
        input_cost = (prompt_tokens / 1_000_000) * model_costs["input"]
        output_cost = (completion_tokens / 1_000_000) * model_costs["output"]
        estimated_cost = input_cost + output_cost

        entry = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "provider": provider,
            "model": model,
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "input_cost": round(input_cost, 6),
            "output_cost": round(output_cost, 6),
            "estimated_cost": round(estimated_cost, 6),
            "operation": operation,
            "trace_id": trace_id,
            "success": success,
            "tokens_estimated": "usage" not in metadata,
            "source": source
        }

        # Persist routing metadata if present (route_picker + routed_to from auto routing)
        if metadata.get("route_picker"):
            entry["routing_model"] = metadata["route_picker"]
        if metadata.get("routed_to"):
            entry["routed_model"] = metadata["routed_to"]

        self._log.append(entry)
        self._save_log()

        logger.debug(
            f"[{trace_id}] Usage logged: {provider}/{model} "
            f"tokens={total_tokens} in=${input_cost:.6f} out=${output_cost:.6f} source={source}"
        )

    def _compute_entry_costs(self, entry: Dict[str, Any]) -> tuple:
        """Compute input/output costs for an entry, recalculating from tokens if missing."""
        ic = entry.get("input_cost", 0.0)
        oc = entry.get("output_cost", 0.0)

        # Recalculate if this is a legacy entry without separate costs
        if "input_cost" not in entry:
            m = entry.get("model", "unknown")
            pt = entry.get("prompt_tokens", 0)
            ct = entry.get("completion_tokens", 0)
            model_costs = self._model_costs.get(m, {"input": 0.0, "output": 0.0})
            ic = (pt / 1_000_000) * model_costs["input"]
            oc = (ct / 1_000_000) * model_costs["output"]

        return ic, oc, ic + oc

    def get_summary(self) -> Dict[str, Any]:
        """Get aggregated usage summary."""
        if not self._log:
            return {
                "total_calls": 0,
                "total_tokens": 0,
                "total_input_cost": 0.0,
                "total_output_cost": 0.0,
                "total_cost": 0.0,
                "by_provider": {},
                "by_model": {},
                "success_rate": 0.0,
                "since": None
            }

        by_provider = defaultdict(lambda: {"calls": 0, "tokens": 0, "input_cost": 0.0, "output_cost": 0.0, "cost": 0.0})
        by_model = defaultdict(lambda: {
            "calls": 0, "prompt_tokens": 0, "completion_tokens": 0,
            "tokens": 0, "input_cost": 0.0, "output_cost": 0.0, "cost": 0.0
        })
        total_tokens = 0
        total_input_cost = 0.0
        total_output_cost = 0.0
        successes = 0

        for entry in self._log:
            p = entry.get("provider", "unknown")
            m = entry.get("model", "unknown")
            t = entry.get("total_tokens", 0)
            pt = entry.get("prompt_tokens", 0)
            ct = entry.get("completion_tokens", 0)

            # Recalculate costs from tokens (handles legacy entries)
            ic, oc, c = self._compute_entry_costs(entry)

            by_provider[p]["calls"] += 1
            by_provider[p]["tokens"] += t
            by_provider[p]["input_cost"] += ic
            by_provider[p]["output_cost"] += oc
            by_provider[p]["cost"] += c

            by_model[m]["calls"] += 1
            by_model[m]["prompt_tokens"] += pt
            by_model[m]["completion_tokens"] += ct
            by_model[m]["tokens"] += t
            by_model[m]["input_cost"] += ic
            by_model[m]["output_cost"] += oc
            by_model[m]["cost"] += c

            total_tokens += t
            total_input_cost += ic
            total_output_cost += oc
            if entry.get("success", True):
                successes += 1

        # Round aggregated costs
        for v in by_provider.values():
            v["input_cost"] = round(v["input_cost"], 6)
            v["output_cost"] = round(v["output_cost"], 6)
            v["cost"] = round(v["cost"], 6)
        for v in by_model.values():
            v["input_cost"] = round(v["input_cost"], 6)
            v["output_cost"] = round(v["output_cost"], 6)
            v["cost"] = round(v["cost"], 6)

        return {
            "total_calls": len(self._log),
            "total_tokens": total_tokens,
            "total_input_cost": round(total_input_cost, 6),
            "total_output_cost": round(total_output_cost, 6),
            "total_cost": round(total_input_cost + total_output_cost, 6),
            "by_provider": dict(by_provider),
            "by_model": dict(by_model),
            "success_rate": round(successes / len(self._log) * 100, 1) if self._log else 0,
            "since": self._log[0].get("timestamp") if self._log else None
        }

    def get_history(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Get recent usage entries (newest first), enriched with costs."""
        entries = list(reversed(self._log[-limit:]))
        # Enrich legacy entries that lack input/output cost
        for entry in entries:
            if "input_cost" not in entry:
                ic, oc, c = self._compute_entry_costs(entry)
                entry["input_cost"] = round(ic, 6)
                entry["output_cost"] = round(oc, 6)
                entry["estimated_cost"] = round(c, 6)
        return entries

    def get_usage_by_trace_id(self, trace_id: str) -> Dict[str, Any]:
        """Get aggregated usage summary for all API calls with a given trace_id."""
        calls = [e for e in self._log if e.get("trace_id") == trace_id]
        if not calls:
            return {}

        models_used = {}
        total_prompt = 0
        total_completion = 0
        total_input_cost = 0.0
        total_output_cost = 0.0

        routing_model = None
        routed_model = None

        for entry in calls:
            ic, oc, c = self._compute_entry_costs(entry)
            m = entry.get("model", "unknown")
            pt = entry.get("prompt_tokens", 0)
            ct = entry.get("completion_tokens", 0)

            total_prompt += pt
            total_completion += ct
            total_input_cost += ic
            total_output_cost += oc

            if m not in models_used:
                models_used[m] = {"calls": 0, "prompt_tokens": 0, "completion_tokens": 0, "input_cost": 0.0, "output_cost": 0.0}
            models_used[m]["calls"] += 1
            models_used[m]["prompt_tokens"] += pt
            models_used[m]["completion_tokens"] += ct
            models_used[m]["input_cost"] += ic
            models_used[m]["output_cost"] += oc

            # Capture routing metadata (first entry that has it wins)
            if not routing_model and entry.get("routing_model"):
                routing_model = entry["routing_model"]
            if not routed_model and entry.get("routed_model"):
                routed_model = entry["routed_model"]

        result = {
            "api_calls": len(calls),
            "models_used": models_used,
            "total_prompt_tokens": total_prompt,
            "total_completion_tokens": total_completion,
            "total_tokens": total_prompt + total_completion,
            "total_input_cost": round(total_input_cost, 6),
            "total_output_cost": round(total_output_cost, 6),
            "total_cost": round(total_input_cost + total_output_cost, 6),
        }
        if routing_model:
            result["routing_model"] = routing_model
        if routed_model:
            result["routed_model"] = routed_model
        return result

    def get_cost_by_model(self) -> Dict[str, Any]:
        """Get cost breakdown by model for chart data."""
        summary = self.get_summary()
        models = []
        for model_name, data in summary.get("by_model", {}).items():
            models.append({
                "name": model_name,
                "input_cost": data.get("input_cost", 0.0),
                "output_cost": data.get("output_cost", 0.0),
                "total_cost": data.get("cost", 0.0)
            })
        models.sort(key=lambda x: x["total_cost"], reverse=True)
        return {"models": models}

    def get_tokens_by_model(self) -> Dict[str, Any]:
        """Get token breakdown by model for chart data."""
        summary = self.get_summary()
        models = []
        for model_name, data in summary.get("by_model", {}).items():
            models.append({
                "name": model_name,
                "prompt_tokens": data.get("prompt_tokens", 0),
                "completion_tokens": data.get("completion_tokens", 0),
                "total_tokens": data.get("tokens", 0)
            })
        models.sort(key=lambda x: x["total_tokens"], reverse=True)
        return {"models": models}

    def get_hourly_breakdown(self, hours: int = 24) -> List[Dict[str, Any]]:
        """Get token usage broken down by hour for chart data."""
        cutoff = datetime.utcnow() - timedelta(hours=hours)
        cutoff_str = cutoff.isoformat() + "Z"

        buckets = defaultdict(lambda: {"tokens": 0, "calls": 0, "cost": 0.0})

        for entry in self._log:
            ts = entry.get("timestamp", "")
            if ts >= cutoff_str:
                # Bucket by hour
                hour_key = ts[:13]  # "2026-02-16T14"
                buckets[hour_key]["tokens"] += entry.get("total_tokens", 0)
                buckets[hour_key]["calls"] += 1
                buckets[hour_key]["cost"] += entry.get("estimated_cost", 0.0)

        # Sort by hour
        result = []
        for key in sorted(buckets.keys()):
            result.append({
                "hour": key,
                "tokens": buckets[key]["tokens"],
                "calls": buckets[key]["calls"],
                "cost": round(buckets[key]["cost"], 6)
            })

        return result

    def get_today_summary(self) -> Dict[str, Any]:
        """Get total tokens and estimated cost for today (since midnight local time approximation, or UTC to be safe). 
           We'll use UTC since everything else is UTC, or just the last 24 hours."""
        # Using UTC for simplicity to match `datetime.utcnow().isoformat()`
        today_start = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0).isoformat() + "Z"
        
        tokens = 0
        cost = 0.0
        
        for entry in self._log:
            if entry.get("timestamp", "") >= today_start:
                tokens += entry.get("total_tokens", 0)
                cost += entry.get("estimated_cost", 0.0)
                
        return {
            "tokens": tokens,
            "cost": round(cost, 6)
        }
